\section*{\LARGE Zusammenfassung}
Computer mit Spracheingabemöglichkeiten sind immer häufiger anzutreffen. Deshalb sind Nutzer vermehrt auf verlässliche Spracherkennungsalgorithmen angewiesen. Dabei ist automatische Sprachidentifizierung der erste und wichtigste Schritt für die eigentliche Spracherkennung. Ohne automatische Sprachidentifizierung sind alle weiteren Erkennungsschritt nutzlos, da weder Sprachklänge richtig verarbeitet noch Grammatikregeln korrekt angewandt werden.

Ein zweiter aktueller Trend in der Informatik ist die erfolgreiche Anwendung von tiefen neuronalen Netzwerken für eine Vielzahl von Aufgabenstellungen. In dieser Arbeit wird ein hybrides, neuronales Netzwerkmodell zur automatischen Identifizierung unterschiedlicher Sprachen mithilfe von \emph{Deep-Learning}-Techniken vorgestellt. Im Speziellen werden mehrere Modelle mit \emph{Convolutional Recurrent Neural Networks} auf menschliche Spracheingaben angewandt und deren Robustheit in verschiedenen Geräuschumgebungen evaluiert.

\emph{Convolutional Neural Networks} haben innerhalb der automatischen Bilderkennungsforschung beachtliche Durchbrüche erzielt. Deshalb wird unsere audiobasierte Forschungsfrage in die Bildverarbeitungsdomäne eingebettet. Darüber hinaus basiert diese Arbeit auf deren etablierten Modellarchitekturen wie beispielsweise dem Inception Netzwerk~\cite{szegedy2015going}. Dabei wird die Effektivität von Spektrogrammbildern als zielführendes Eingabemedium analysiert. Zusätzlich werden weitere Audiorepräsentationen und weiterführende Publikationen vorgestellt.

Insbesondere die Verfügbarkeit von großen Datensätzen kommen Deep-Learning-Systemen zugute. Unsere Modelle werden auf mehr als \num{1000}~Stunden an Sprachaufnahmen in sechs verschiedenen Sprachen trainiert: Englisch, Deutsch, Französisch, Spanisch, Mandarin und Russisch. Die Datengrundlage bilden Reden und Sitzungen des Europäischen Parlaments sowie YouTube-Kanäle verschiedener Nachrichtensender wie dem BBC.

Unser leistungsfähigstes Convolutional Recurrent Neural Network erreicht eine Erkennungsgenauigkeit und ein F-Maß von~\SI{96}{\percent} auf dem Nachrichtendatensatz. Unser Ansatz stellt eine konstante Verbesserung gegenüber allen getesteten Convolutional Neural Networks dar. Die Modelle werden zusätzlich in verschiedenen Szenarien mit künstlich veränderten Daten evaluiert. Dabei fügen wir Störgeräusche wie Rauschen, Geknister und Hintergrundmusik zu den Daten hinzu und messen einen Genauigkeitsverlust von jeweils \num{5}~Prozentpunkten (PP), \num{3}~PP und \num{7}~PP gegenüber den Originaldaten. Auf dem kleineren EU-Datensatz erreichen wir eine Genauigkeit und ein F-Maß von~\SI{98}{\percent}.
