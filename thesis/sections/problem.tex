\section{The Language Identification Problem}
\label{sec:lid}

\subsection{Language Identification as the key to speech tasks}

Automatic language identification (\ac{lid}) is the process of determining the language spoken in an audio recording. The language identification systems proposed in this thesis consume audio recordings and use deep learning techniques to do an automated classification of the recording's source language.
Language identification is often the first step in a natural language processing pipelines. Automatic language identification systems can serve a wide variety of applications from industry and research to entertainment. 

In contrast to LID systems, automatic speech recognition (\ac{asr}) is the task of transcribing spoken language into readable text, sometimes also known as speech-to-text system. Selecting the correct input language for these systems is crucial for transcribing single letters into meaningful words and correct grammar. Many commercially available ASR system require manual setting of the input language and would benefit greatly from an automated language identification system as part of their processing pipeline.

Many call center operators benefit from LID systems by automatically routing telephone calls to connect a caller with a suitable native speaker. This approach can be used both for customer care hotlines connecting callers with help desk agents as well governments agencies such as emergency telephone services. Muthusamy et al. report that manual matching emergency calls to US law enforcement agencies with native speaking agents can involve a significant delay of up to three minutes. Automatic language identification systems could speed up this process and efficiently support human agents~\cite{muthusamy1994reviewing}.

Similarly to language identification some research is focused on dialect detection. To foster research in this field, DARPA established the TIMIT dataset for dialect identification of North American speakers~\cite{garofolo1993darpa}. The dataset features eight major North American dialects and has long been the default corpus for comparative research on lid systems.
Recently, Germany's Federal Office for Migration and Refugees (BAMF) announced the plans for using dialect identification systems\footnote{\url{http://www.theverge.com/2017/3/17/14956532/germany-refugee-voice-analysis-dialect-speech-software, accessed 13.04.2017}} as an additional resource in identifying a person's origin.

Language identification is also the first step to translation tasks. At the time of this writing we discovered that not even the Google Translate mobile app has automated language detection to determine the input language for a speech sample. Automated input language detection is available for written texts but Google Translate's voice input feature is only available for use after manually selecting an input language. We believe that having an automated language detection system could be extremely helpful to users. 

An ever increasing number of people connect to the internet or communicate with each other using their smartphone. While touchscreen input can be complicated in some situations, the demand for voice interactions grows steadily. Many tasks can already be solved through voice input. This hands free, voice enabled interaction is trend that we see in other industries such as automative computing as well.

Automatic LID systems and machine intelligence are also helpful for some entertainment companies. When we first started working on this thesis we were briefly inspired by the challenges of Berlin based startup Dubsmash\footnote{\url{https://www.dubsmash.com/}, accessed 13.04.2017}. Their app lets user's create a mashup of a large variety of existing songs, movie quotes, or other voice snippets with a ten-second video recording of the user. The resulting video clip can be shared with friends and usually features a funny and personal reinterpretation of the audio source's original context. The success of the app is directly proportional to user's interest in the offered sound clips. In some cases, however, users were offered clips in foreign languages which were often perceived as not funny or inappropriate. In this case, a LID system could be used to classify the language of the millions of audio snippets available in their library. Consequently, only sounds in the user's native language can be recommended to the user.


\subsection{Task Specification in This Thesis}
In this thesis we propose a language identification (\ac{lid}) system for classifying the languages of a given audio recording. Our system is trained using human voices recordings. We evaluate the suitability of convolutional neural networks for a LID system. Finally, this approach is extended with a recurrent neural network to compose a hybrid network known as convolutional recurrent neural network (\ac{crnn}). The system 's performance is evaluated on a set of news broadcasts and speeches made by members of the European Parliament. We further assess the system's robustness to noisy environments and background music. This thesis states the following hypotheses:

\begin{enumerate}
	\item Convolutional neural networks can be successfully used for language identification tasks with high accuracy.
	\item Spectrogram images are a suitable input representation for learning audio features.
	\item Convolutional recurrent neural networks improve the classification accuracy for our LID task compared to a CNN based approach.
\end{enumerate}


