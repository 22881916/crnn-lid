\section{The Language Identification Problem}
\label{sec:lid}

\subsection{Language Identification as the key to speech tasks}

Automatic language identification (\ac{lid}) is the process of determining the language spoken in an audio recording. The language identification systems proposed in this thesis consumes audio recordings and uses deep learning techniques to do an automated classification of the recording's source language.
Language identification is often the first step in a natural language processing pipelines. Automatic speech recognition (\ac{asr}) is the task of transcribing spoken language into readable text, sometimes also known as speech-to-text system. In contrast to LID systems, ASR uses a complex ensemble of multiple machine learning models, one of which is usually a language model. Selecting the correct language model is crucial to combine the transcription of single letters into meaningful words and correct grammar.
Automatic language identification systems can serve a wide variety of applications from industry and research to entertainment. 

Many call center operators benefit for LID systems by automatically routing telephone calls to connect a caller with a native speaker. This approach can be used both for customer care hotlines connecting callers with help desk agents as well governments agencies such as emergency telephone services. Muthusamy et al\cite{muthusamy1994reviewing} report that manual matching emergency calls to US law enforcement agencies with native speaking agents can involve a significant delay of up to three minutes. Automatic language identification systems could speed up this process and efficiently support human agents.

Similarly to language identification some research is focused on dialect detection. To foster research in this field DARPA established the TIMIT\cite{garofolo1993darpa} dataset for language identification of North American speakers. The dataset features either major North American dialects and has long been the default corpus for comparative research on lid systems.
Recently, Germany's Federal Office for Migration and Refugees (BAMF) announced the plans for using dialect identification systems\footnote{\url{http://www.theverge.com/2017/3/17/14956532/germany-refugee-voice-analysis-dialect-speech-software, accessed 13.04.2017}} as an additional resource in identifying a person's origin.

Language identification is also the first step to translation tasks. At the time of this writing we discovered that not even the Google Translate mobile app has automated language detection to determine the input language for a speech sample. Automated input language detection is available for written texts but Google Translate's voice input feature is only available for use after manually selecting an input language. We believe that having an automated language detection system could be extremely helpful to users. 

An ever increasing number of people connect to the internet or communicate with each other using their smartphone. While touchscreen input can sometime be complicated the demand for voice interactions grow. Already many tasks can be solved through voice input. This hands free, voice enabled interaction is trend that we see in other industries such as cars as well.

Automatic LID systems and machine intelligence are also helpful for some entertainment companies. When we first started working on this thesis we were briefly inspired by the challenges of Berlin based startup Dubsmash\footnote{\url{https://www.dubsmash.com/}, accessed 13.04.2017}. Their app lets user's create a mashup of a large variety of existing songs, movie quotes or other voice snippets with a ten second video recording of the user. The resulting video clip can be shared with friends and usually features a funny and personal reinterpretation of the audio source's original context. The success of the app is directly proportional to user's interest in the offered sound clips. In some cases, however, users were offered clips in foreign languages which were often perceived as not funny or inappropriate. A LID system can be used to classify the language of the millions of audio snippets available in their library. Consequently, only sounds in the user's native language can be recommended to the user.


\subsection{Task Specification in This Thesis}
In this thesis we propose a language identification (\ac{lid}) system for classifying the languages of a given audio recording. We make use of human voices recordings to train the  system. We evaluate the suitability of convolutional neural networks for a LID system. We extend this approach with a recurrent neural network to form a hybrid network known as convolutional recurrent neural network (\ac{crnn}). The system 's performance is evaluated on a set of news broadcasts and speeches made by members of the European Parliament. We further assess the system's robustness to noisy environments and background music. We state the following hypotheses:

\begin{enumerate}
	\item Convolutional neural networks can be successfully used for language identification tasks with high accuracy.
	\item Spectrogram images are a suitable input representation for learning audio features.
	\item Convolutional recurrent neural networks improve the classification accuracy for our LID task compared to a CNN based approach.
\end{enumerate}


