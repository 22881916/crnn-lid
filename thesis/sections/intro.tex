\section{Introduction}

% context
% identify problem
% minimal related work
% contributions â†’ sehr explizit, nicht zu detailliert
% structure

Computers have become ubiquitous in our daily lives. Millions of people around the world use speech input to conveniently interact with their devices.
Speech input excels in certain situations, such as hands-free interaction, when driving, or as an efficient alternative to text input instead of typing on small screens.
In all these interaction scenarios, the first step to understanding users is to correctly identify the input language. In some settings, computers might well use metadata such as known locations or the system's default languages for this task. Yet often times, it is much preferred to infer a language directly from the speech input. This can be the case in countries with more than one official language or for multilingual users. 

In the same timeframe of this development, deep learning and artificial neural networks have become the state of the art for many pattern recognition problems. 
Deep convolutional networks have become the best-performing method for solving various computer vision tasks, such as image classification~\cite{russakovsky2015imagenet}, object detection~\cite{russakovsky2015imagenet, everingham2010pascal}, text detection~\cite{Yang2016SceneTextRegAR, jaderberg2014synthetic}, semantic segmentation~\cite{dai2016instance, girshick2014rich}, object tracking~\cite{nam2016learning}, image retrieval~\cite{tolias2015particular}, and many others. 
The task of automatic language identification, however, was previously mainly done through classical machine learning algorithm approaches, which relied on domain-specific expert knowledge in the field of audio signal processing.



\subsection{Contributions}
In this thesis, we propose a novel system for language identification using deep learning techniques. For this, we first transfer the given audio classification problem into an image-based task. To classify languages on given speech input, we then apply image recognition algorithms on the transformed data based on convolutional recurrent neural networks. Hence, we benefit from the aforementioned advances in the computer vision community by transferring the language identification problem from the audio context to the image domain.

Our contributions can be summarized as follows:
\begin{itemize}
	\item We investigate the suitability of \emph{convolutional neural networks} (\ac{cnn}) for the task of language identification. As a solution to this challenge, we propose a hybrid network, combining the descriptive powers of convolutional neural networks with the ability of \emph{recurrent neural networks} (\ac{rnn}) to capture temporal features. This approach is called \emph{convolutional recurrent neural network} (CRNN).
	\item We implement a CNN and a CRNN system in Python using the deep learning frameworks Keras and TensorFlow. We show that the CRNN approach outperforms all other methods in every single evaluation with respect to accuracy and F1~score.
	\item To train our system, we compile our own large-scale dataset of audio recordings. We explain how we obtain and process more than a thousand hours of suitable human speech recording for our task.
	\item We assess several machine learning metrics on our system with respect to our test data. Furthermore, we investigate the influence of noisy environments on our system. We discuss the system's ability to differentiate between several languages and extend the system to even more languages.
	\item To showcase our system, we develop a web service demo application employing our best-performing model, which we published for use by others.
\end{itemize}


\subsection{Outline of the Thesis}
This thesis is structured as follows. In Chapter~\ref{sec:lid}, we introduce the language identification problem and state our research hypotheses. Chapter~\ref{sec:theoretical_background} explains the theoretical background of the deep learning techniques and algorithms used in this thesis. Chapter~\ref{sec:related_work} introduces related work and alternative approaches to the language identification task (\ac{lid}). In Chapter~\ref{sec:datasets}, we describe the audio datasets we collected for training and evaluating our system. Implementation details are outlined in Chapter~\ref{sec:implementation}. Further, we describe the network architectures of our models. Evaluation results are reported and discussed in Chapter~\ref{sec:evaluation}, followed by various experiments for assessing the robustness of our system to music and noise. In Chapter~\ref{sec:demo}, we propose a web service to showcase a potential use case for language identification. Finally, we close this thesis by summarizing our observations in Chapter~\ref{sec:summary} and outline future work.
