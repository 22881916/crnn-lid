\section{Conclusion and Future Work}
\label{sec:summary}
This last chapter presents high-level insights and finally comments on
future work and prospects concerning the discussed topics.
It further outlines the contribution of this thesis and concludes the work done
in the research field.

\subsection{Future Work}
The overall trend within the deep learning community over the past few years has been to increase the network depth by adding more and more layers. Supporting this development, however, is becoming increasingly more difficult. Very deep networks are harder to train and require ever more computing time. One way to gain higher accuracy scores is to change the design and architecture of the network. He et al. recently proposed the technique of deep residual learning\cite{he2016deep} to tackle these challenges. In their network architecture they introduce small building blocks of two convolutional layers in which the second layer receives the original input of the first layer in addition to the output of its predecessor~\cite{he2016deep}. Using this approach, they were able to train \emph{ResNet} with 152 layers and bested the previous state of the art in the ILSVRC 2015 challenge. Similarly, Szegedy et al. introduced the latest iteration of their Inception networks using these residual connections\cite{szegedy2016inception} as well.

For future work, we think that using deep residual neural network for the convolutional part of our architecture holds much promise. In this thesis we were able to measure our best results using the previously state-of-the-art \emph{Inception-v3} network for computer vision tasks. In the future we believe that using \emph{Inception-v3} or the ResNet architecture should improve our results even further and perhaps add more robustness to noise as well.

As part of our training process, we pretrained our convolutional neural networks before assembling them to the complete CRNN. The complete CRNN then reused the learned weights of the convolutional layers and finetuned them by further, joint training with the LSTM part. This \emph{transfer learning} approach is fairly simple, yet effective. Unfortunately, parallel to finetuning the network on the new data it starts to forget previously learned features. This is referred to as catastrophic forgetting. Rusu et al. introduced \emph{Progressive Neural Networks}~\cite{rusu2016progressive} as a novel approach to \emph{transfer training}. This technique leverages prior knowledge via so called lateral connections to previously learned features. For future work, we think it is worthwhile to evaluate whether this approach could be helpful in improving our transfer learning steps.

We formulated our research problem as a classification problem for language identification. The limitation of this, however, is that our models are only able to accurately predict languages that have been part of the training corpus. In other words, we are unable to identify any language unknown to the system. An interesting, yet slightly different research field, is metric learning. This approach is able to measure a difference or a score between its classes. So for example with metric learning, a sample would receive a score whether it was closer related to German or English. The advantage of this approach is that the system is no longer limited to only the training languages. For unknown languages one could still assess, whether a language is more similar to one then another. Conversely, this also allows to judge how different an input is to any language know to the system, something that is not possible with our approach.

In this thesis we evaluated our networks on six different input languages. In the future our system could be extended to cover even more languages. In our work we did not evaluate the effectiveness of the presented approach on similar tasks such as dialect identification. Future work could evaluate the accuracy of our approach on the fine grained differences between dialects and accents of a language.

Throughout this work we evaluated our models' robustness to white noise and background music noise. We also tried evaluating our models on songs but found the performance to be inadequate for our needs. In our case the biggest problem with songs was the fact that the speech frequencies are completely masked by the frequencies of the different instruments. Future work could focus on language identification for songs and music.

Our approach relies on extracting and classifying a sequence of intermediate languages representation created from spectrogram image inputs. Within the automatic speech recognition (ASR) community there is related work that extracts and classifies a sequence of phonemes~\cite{song2015end}. Instead of matching these phoneme sequences to words one could use these to classify a target language. This is an alternative approach to the one presented in this thesis and could be used to compare the effectiveness and robustness of the two methods. Another interesting idea was introduce by Google's \emph{Wavenet}~\cite{van2016wavenet}. Utilizing dilated convolutions for speech recognition they were able to capture a longer receptive field while being much cheaper to compute than LSTMs. Further, \emph{Wavenet} operates on raw audio signals forgoing the need for spectrogram features.  Even though they evaluated \emph{Wavenet} for automatic speech recognition, it could likely be adopted to language identification as well. 

\subsection{Conclusion}
In this thesis we presented several neural network architectures aimed at the task of solving the language identification problem. We employed CNNs and CRNNs to infer the language of a given audio sample directly from its spectrogram representation. 

We proposed three hypotheses and conducted experiments to verify their validity. We confirmed that, first convolutional neural networks are an effective, high-accuracy solution for language identification tasks. Second, spectrogram images are a suitable input representation for learning audio features. Third, convolutional recurrent neural networks consistently improve the classification accuracy throughout all experiments compared to a plain, CNN-based approach.

We present and discuss the availability and suitability of various datasets for LID. For our research we compiled and processed more than a thousand hours of speech data from public sources. On the one hand, this thesis gathered speeches and press conferences from the European Parliament. On the other hand, we collected audio from news broadcasts hosted on YouTube.

To judge the effectiveness and validity of our research in several scenarios, we augmented our test dataset with additional white noise, crackling noise, and background music and tested the robustness of our neural networks. We report a decrease in recognition accuracy under these noisy situations.

In this work, we explored different neural network architectures and comment on our setup of hyperparameters. Our best performing CRNN model is based the Inception-v3 architecture and was able to achieve an accuracy and F1~score of~\num{0.96} and~\num{0.96}, respectively.

Initially, we trained and evaluated our models on four languages---English, German, French, and Spanish. We were content to find that the approach presented in this thesis could be transferred to other languages as well. During our experiments we added Mandarin Chinese and Russian. The frequency features learned by our system are, indeed, language-independent and we were able to expand our system to these two new languages without any large modifications.

This thesis presents a recent approach to solve the language identification task with deep neural networks. Further research needs to be deducted to improve the robustness against noise and discover new kinds of layers and architectures to support even higher accuracies in this field. 
