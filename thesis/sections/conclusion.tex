\section{Conclusions and Future Work}
\label{sec:summary}
This last chapter presents high-level insights and finally comments on
future work and prospects concerning the discussed topics.
This chapter further outlines the contributions of this thesis and concludes the work done
in the research field.

\subsection{Future Work}
The overall trend within the deep learning community over the past few years was to increase the network depth by adding more and more layers. Supporting this development, however, is becoming increasingly difficult. Very deep networks are harder to train and require ever more computing time. One way to gain higher accuracy scores is to change the design and architecture of the network. He et al. recently proposed the technique of \emph{deep residual learning} to tackle these challenges~\cite{he2016deep}. In their network architecture, the authors introduce small building blocks of two convolutional layers, in which the second layer receives the original input of the first layer in addition to the output of its predecessor~\cite{he2016deep}. Using this approach, the authors were able to train the so-called ResNet with \num{152}~layers and bested the previous state of the art in the ILSVRC 2015 challenge. Similarly, Szegedy et al. introduced the latest iteration of their Inception networks using these residual connections as well~\cite{szegedy2016inception}.

For future work, we think that using deep residual neural network for the convolutional part of our architecture holds much promise. In this thesis, we were able to measure our best results using the previously state-of-the-art \emph{Inception-v3} network for computer vision tasks. In the future, we believe that using Inception-v3 or the ResNet architecture should improve our results even further and, perhaps, add more robustness to noise as well.

As part of our training process, we pretrained our convolutional neural networks before assembling them to the complete CRNN. The complete CRNN then reused the learned weights of the convolutional layers and fine-tuned them by a further, joint training step with the LSTM part. This \emph{transfer learning} approach is fairly simple yet effective. Unfortunately, in parallel to fine-tuning the network on the new data, the CRNN starts to forget previously learned features. This is referred to as \emph{catastrophic forgetting}. Rusu et al. introduced \emph{Progressive Neural Networks} as a novel approach to \emph{transfer training}~\cite{rusu2016progressive}. This technique leverages prior knowledge via so-called \emph{lateral connections} to previously learned features. For future work, we think that it is worthwhile to evaluate whether this approach could be helpful in improving our transfer learning steps.

We formulated our research problem as a classification problem for language identification. The limitation of this is, however, that our models are only able to accurately predict languages that were part of the training corpus. In other words, we are unable to identify any language unknown to the system. An interesting, yet slightly different research field, is metric learning. This approach is able to measure a difference or a score between its classes. For example, with metric learning, a sample would receive a score indicating whether it was more closely related to either German or English. The advantage of this approach is that the system is no longer limited to only the training languages. For unknown languages, one could still assess whether a language is more similar to one than another. Conversely, this also allows for judging how different an input is to any language known to the system, something that is not possible with our approach.

In this thesis, we evaluated our networks on six different input languages. In the future, our system could be extended to cover even more languages. In our work, we did not evaluate the effectiveness of the presented approach on similar tasks such as dialect identification. Future work could evaluate the accuracy of our approach on the fine-grained differences between dialects and accents of a language.

Throughout this work, we evaluated our models' robustness to white noise and background music noise. We also tried evaluating our models on songs but found the performance to be inadequate for our needs. In our case, the biggest problem with songs was the fact that the speech frequencies are completely masked by the frequencies of the instruments. Future work could focus on language identification for songs and music.

Our approach relies on extracting and classifying a sequence of intermediate language representations created from spectrogram image inputs. Within the automatic speech recognition community (ASR), there is related work on extracting and classifying sequences of phonemes~\cite{song2015end}. Instead of matching these phoneme sequences to words, one could use these to classify a target language. This is an alternative approach to the one presented in this thesis and could be used to compare the effectiveness and robustness of the two methods. Another interesting idea was introduced by Google's \emph{Wavenet}~\cite{van2016wavenet}. By utilizing dilated convolutions for speech recognition, the authors were able to capture a longer receptive field, which is much cheaper to compute than LSTMs. Further, \emph{Wavenet} operates on raw audio signals forgoing the need for spectrogram features.  Even though \emph{Wavenet} was evaluated for automatic speech recognition, it could likely be adopted to language identification as well. 

\subsection{Conclusions}
In this thesis, we presented several neural network architectures aimed at the task of solving the language identification problem. We employed CNNs and CRNNs to infer the language of given audio samples directly from their spectrogram representation. 

We proposed three hypotheses and conducted experiments to verify their validity. We confirmed that, first, convolutional neural networks are an effective, high-accuracy solution for language identification tasks. Second, spectrogram images are a suitable input representation for learning audio features. Third, convolutional recurrent neural networks consistently improve the classification accuracy throughout all experiments compared to a plain, CNN-based approach.

We presented and discussed the availability and suitability of various datasets for LID. For our research, we compiled and processed more than a thousand hours of speech data from public sources---one the one hand, speeches and press conferences from the European Parliament, and on the other hand, audio from news broadcasts hosted on YouTube.

To judge the effectiveness and validity of our research in several scenarios, we augmented our test dataset with additional white noise, crackling noise, and background music and tested the robustness of our neural networks. We reported a decrease in recognition accuracy under these noisy situations.

In this work, we explored different neural network architectures and commented on our setup of hyperparameters. Our best-performing CRNN model is based on the Inception-v3 architecture and was able to achieve an accuracy and F1~score of~\num{0.96} and~\num{0.96}, respectively.

Initially, we trained and evaluated our models on four languages---English, German, French, and Spanish. We were content to find that the approach presented in this thesis could be transferred to other languages as well. During our experiments, we added Mandarin Chinese, and Russian. The frequency features learned by our system are, indeed, language-independent, and we were able to expand our system to these two new languages without any large modifications.

This thesis presents a recent approach to solve the language identification task with deep neural networks. Further research needs to be deducted to improve the robustness against noise and to discover new kinds of layers and architectures to support even higher accuracies in this field. 
