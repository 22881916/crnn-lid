\section{Conclusion and Future Work}
\label{sec:summary}

\subsection{Conclusion}
\subsection{Future Work}
The overall trend within the deep learning community over the past few years has been to increase the network depth by adding more and more layers. This approach, however, is becoming increasingly more difficult. These very deep networks are harder to train and need more computing time to calculate. One way to gain higher accuracy scores is by changing the design and architecture of the network itself. He et al. propose the technique of deep residual learning\cite{he2016deep}. In their network architecture the introduce small building blocks of two convolutional layers in which the second layer additionally receives the original input of the first layer. \cite{he2016deep} Using this approach they were able to train ResNet with 152 layers and bested the previous state of the art in the ILSVRC 2015 challenge. Similarly, Szegedy et al. introduced the latest iteration of their Inception networks using residual connections\cite{szegedy2016inception} as well.\\
For future work we think that using deep residual neural network for the convolutional part of our architecture holds much promise. In this thesis we were able to measure our best results using the previously state of the art Inception-v3 network for computer vision tasks. In the future we believe that using Inception-v3 or the ResNet architecture should improve our results even further and perhaps add more noise robustness as well.

As part of our training process we pretrained our convolutional neural networks before assembling them to the complete CRNN. The complete CRNN then reused the learned weights of the convolutional layers and finetuned them by further joint training with the LSTM part. This transfer learning approach is fairly simple, yet effective. The problem with this setup is that during the finetuning process previously learned features can be forgotten. Rusu et al. introduced Progressive Neural Networks\cite{rusu2016progressive} as a novel approach to transfer training. This technique leverages prior knowledge via lateral connections to previously learned features. For future work we think it worthwhile to evaluate wether this approach could be helpful in improving our transfer learning.

We formulated our research problem as a classification task to match our language identification task. The limitation of this, however, is that our models are only able to accurately predict languages that have been part of the training corpus. In other words, we are unable to identify any language unknown to the system. An interesting, yet slightly different research field, is metric learning. This approach is able to measure a difference or score between its classes. So for example with metric learning a sample would receive a score wether it was closer to German or English. The advantage here is that you are no longer limited to only the training languages. For unknown languages one could still assess wether a language is more similar to one then another. Adversely, this also allows to judge how different an input is to any language know to the system, something that is not possible with our approach.

In this thesis we evaluated our network on six different input languages. In the future this could be extended to cover even more languages. In our work we did not evaluate the effectiveness of this approach for dialect identification. Future work could evaluate the accuracy of our approach on the fine grained differences between dialects and accents of a language.

Throughout this thesis we evaluated our models' robustness to white noise and background music noise. We also tried evaluating our models on songs but found the performance to be inadequate. The biggest problem with songs is that the speech frequencies are completely masked by the frequencies of the different instruments. Future work could focus on language identification for songs and music.

Our approach relies on extracting and classifying a sequence of intermediate languages representation of spectrogram image inputs. Within the automatic speech recognition (ASR) community there is related work\cite{song2015end}that extracts and classifies a sequence of phonemes. Instead of matching these phoneme sequences to words one could use these to classify a target language. This is an alternative approach to the one presented here and could be used to compare the two. Another interesting approach was introduce by Google's Wavenet\cite{van2016wavenet}. Utilizing dilated convolutions for speech recognition they were able to capture a longer receptive field while being much cheaper to compute than LSTMs. Further, it operates on raw audio signals forgoing the need for spectrogram features.  Even though they evaluated Wavenet for automatic speech recognition it could likely be adopted to language identification as well. 

